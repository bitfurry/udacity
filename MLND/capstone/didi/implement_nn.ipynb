{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT THIS NOTEBOOK\n",
    "## Purpose\n",
    "This notebook attempts to fit a neural network based model using TensorFlow.    \n",
    "Results of the model fitting are analyzed.\n",
    "## Input\n",
    "'data_set.pickle' generated by 'data_processing.ipynb'.\n",
    "## Output\n",
    "Results of model fitting: plots, parameters and scores.\n",
    "## Tasks Performed\n",
    "* Load library packages\n",
    "* Load pickle file\n",
    "* Split data into train & test sets\n",
    "    * Train: weeks 1 & 2, Test: week 3\n",
    "    * Perform feature scaling\n",
    "* Run the following experiments:\n",
    "    * Sing\n",
    "    * Batch gradient descent with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD LIBRARY PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in packages from os, tensorflow, numpy, pandas, matplotlib, seaborn, sklearn & six\n"
     ]
    }
   ],
   "source": [
    "# Import the required library packages\n",
    "import os\n",
    "import re\n",
    "import timeit\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Settings for matplotlib, Seaborn\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set font sizes for matplots\n",
    "plt.rcParams.update({'font.size': 15, \n",
    "                     'legend.fontsize': 'medium', \n",
    "                     'axes.titlesize': 'medium', \n",
    "                     'axes.labelsize': 'medium'})\n",
    "\n",
    "print 'Read in packages from os, tensorflow, numpy, pandas, matplotlib, seaborn, sklearn & six'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PICKLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ptrain_set (199584, 55)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'data_set.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    pdata_set = save['data_set']\n",
    "    del save\n",
    "    print 'Loaded ptrain_set', pdata_set.shape\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['district_id', 'num_day', 'time_slot', 'week_day', 'demand',\n",
       "       'demand_t-1', 'demand_t-2', 'demand_t-3', 'supply', 'supply_t-1',\n",
       "       'supply_t-2', 'supply_t-3', 'gap', 'weather', 'temperature',\n",
       "       'pollution', 'poi_pc1', 'poi_pc2', 'poi_pc3', 'poi_pc4',\n",
       "       'poi_cluster', 'tj_lvl1', 'tj_lvl2', 'tj_lvl3', 'tj_lvl4', 'dist_0',\n",
       "       'dist_1', 'dist_2', 'dist_3', 'dist_4', 'dist_5', 'dist_6',\n",
       "       'numday_0', 'numday_1', 'numday_2', 'numday_3', 'numday_4', 'ts_0',\n",
       "       'ts_1', 'ts_2', 'ts_3', 'ts_4', 'ts_5', 'ts_6', 'ts_7', 'weekday_0',\n",
       "       'weekday_1', 'weekday_2', 'poi_0', 'poi_1', 'poi_2', 'wthr_0',\n",
       "       'wthr_1', 'wthr_2', 'wthr_3'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata_set.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA INTO TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use weeks 1 & 2 for training, week 3 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train, X_test: (133056, 55) (66528, 55) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_days     = range(1,15)\n",
    "test_days      = range(15, 22)\n",
    "\n",
    "X_train     = pdata_set[(pdata_set['num_day'].isin(train_days))]\n",
    "X_test      = pdata_set[(pdata_set['num_day'].isin(test_days))]\n",
    "\n",
    "print \"Shape of X_train, X_test:\", X_train.shape, X_test.shape, \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scaled features for train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gap_predictors = ['demand_t-1', 'demand_t-2', 'demand_t-3',\n",
    "                  'supply_t-1', 'supply_t-2', 'supply_t-3',\n",
    "                  'poi_pc1', 'poi_pc2',\n",
    "                  'tj_lvl1', 'tj_lvl2', 'tj_lvl3',\n",
    "                  'ts_0', 'ts_1', 'ts_2', 'ts_3', 'ts_4', 'ts_5', 'ts_6', 'ts_7',\n",
    "                  'pollution', 'temperature',\n",
    "                  'wthr_0', 'wthr_1', 'wthr_2', 'wthr_3'\n",
    "                 ]  \n",
    "\n",
    "gX_train = []\n",
    "gy_train = []\n",
    "gX_test  = []\n",
    "gy_test  = []\n",
    "\n",
    "# Use StandardScaler to achieve zero mean and unit variance\n",
    "# Generate two scalers: input and target\n",
    "input_scaler = StandardScaler().fit(pdata_set[gap_predictors])\n",
    "target_scaler = StandardScaler().fit(pdata_set['gap'])\n",
    "\n",
    "# Scale both training & test data\n",
    "gX_train  = input_scaler.transform(X_train[gap_predictors])\n",
    "gy_train  = target_scaler.transform(X_train['gap'])\n",
    "\n",
    "gX_test = input_scaler.transform(X_test[gap_predictors])\n",
    "gy_test = target_scaler.transform(X_test['gap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_predictors = [0,3,1,5,2,8,4,19]\n",
    "\n",
    "train_dataset, valid_dataset, train_labels, valid_labels = train_test_split(gX_train[:, nn_predictors], gy_train, test_size=0.33)\n",
    "test_dataset = gX_test[:, nn_predictors]\n",
    "test_labels  = gy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89147, 8) (43909, 8) (89147,) (43909,)\n"
     ]
    }
   ],
   "source": [
    "print train_dataset.shape, valid_dataset.shape, train_labels.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENT FUNCTIONS FOR COMMON TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Demand Supply Gap Metrics based on provided fit functions\n",
    "# Assumes expected values for gap is in namesake column\n",
    "def gap_estimate(**kwargs):\n",
    "    \"\"\"\n",
    "    Generate scores for gap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gX_train  : array containing train features\n",
    "    gX_test   : array containing test features\n",
    "    g_fitfunc : function to use for predicting\n",
    "    \"\"\"\n",
    "    \n",
    "    gX_train     = kwargs[\"gX_train\"]\n",
    "    gX_test      = kwargs[\"gX_test\"]\n",
    "    g_fitfunc    = kwargs[\"g_fitfunc\"]\n",
    "    \n",
    "    print \"\\n\\nGAP FORECASTING\"\n",
    "    print     \"===============\"\n",
    "\n",
    "    # Generate predictions for train & test sets\n",
    "    gy_pred_train    = target_scaler.inverse_transform(g_fitfunc.predict(gX_train))\n",
    "    gy_pred_test     = target_scaler.inverse_transform(g_fitfunc.predict(gX_test))\n",
    "\n",
    "    # Extract expected train & test values\n",
    "    gy_train    = X_train['gap']\n",
    "    gy_test     = X_test['gap']\n",
    "\n",
    "    # Evaluate scores and print results\n",
    "    print_score(gy_train, gy_pred_train, gy_test, gy_pred_test) \n",
    "    return\n",
    "\n",
    "def print_score(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Present the MSE, R^2 and MAPE scores for train & test sets as a table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train      : Array containing expected values for train set\n",
    "    y_pred_train : Array containing predicted values for train set\n",
    "    y_test       : Array containing expected values for test set\n",
    "    y_pred_test  : Array containing predicted values for test set\n",
    "    \"\"\"\n",
    "    \n",
    "    m2score_train    = metrics.mean_squared_error(y_train,    y_pred_train)\n",
    "    m2score_test     = metrics.mean_squared_error(y_test,     y_pred_test)\n",
    "\n",
    "\n",
    "    r2score_train    = metrics.r2_score(y_train,    y_pred_train)\n",
    "    r2score_test     = metrics.r2_score(y_test,     y_pred_test)\n",
    "\n",
    "    # Assumes data is for 144 time slots, 14 days (train), 7 days (test)\n",
    "    mpscore_train    = mape_score(y_train,    y_pred_train, ((144*14)-1))\n",
    "    mpscore_test     = mape_score(y_test,     y_pred_test, ((144*7)-1))\n",
    "\n",
    "\n",
    "    sets_list = [\"TRAIN\", \"TEST\"]\n",
    "\n",
    "    m2_scores = [m2score_train, m2score_test]\n",
    "    r2_scores = [r2score_train, r2score_test]\n",
    "    mp_scores = [mpscore_train, mpscore_test]\n",
    "\n",
    "\n",
    "    print '\\t\\tMEAN^2\\t\\tR2\\t\\tMAPE'\n",
    "\n",
    "    for s, m, r, mp in zip(sets_list, m2_scores, r2_scores, mp_scores):\n",
    "        print '{0:10}\\t{1:.3f}\\t\\t{2:.3f}\\t\\t{3:.3f}' .format(s, m, r, mp)\n",
    "\n",
    "\n",
    "def mape_score(exp, pred, q):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate the MAPE score value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exp  : Array containing expected values\n",
    "    pred : Array containing predicted values\n",
    "    q    : Constant representing (number of days * number of time slots) - 1\n",
    "    \"\"\"\n",
    "    \n",
    "    mape = 0.0\n",
    "    n = 66.0\n",
    "    \n",
    "    for gap, gapX in zip(exp, pred):\n",
    "        if gap > 0:\n",
    "            mape += 1.0 * abs((gap-gapX)/gap)\n",
    "    return (mape/(n*q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a scorer function using the MAPE metric\n",
    "# Use the training data size (144 time slots * 14 days) for q value\n",
    "\n",
    "mape_scorer = make_scorer(mape_score, greater_is_better=False, q=((144*14)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Learning & Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_learningcurves(sparse=False,**kwargs):\n",
    "    ''' Generate learning curves by varying training sizes.\n",
    "    Use Training vs Cross-validation curves.\n",
    "    \n",
    "    Arguments:\n",
    "    gX_train -- Input features for training\n",
    "    gy_train -- Target values for training\n",
    "    alg -- Algorithm used for estimation\n",
    "    alg_name -- Name of the algorithm\n",
    "    \n",
    "    Returns:\n",
    "    Generates the learning curves plot.\n",
    "    '''\n",
    "   \n",
    "    gX_train      = kwargs[\"gX_train\"]\n",
    "    gy_train      = kwargs[\"gy_train\"]\n",
    "    alg           = kwargs[\"alg\"]\n",
    "    alg_name      = kwargs[\"alg_name\"]\n",
    "    \n",
    "    if (sparse):\n",
    "        train_sizes = np.linspace(.01, 1.0, 6)\n",
    "    else:\n",
    "        train_sizes = np.linspace(.01, 1.0, 20)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    X, y = gX_train, gy_train\n",
    "    title = 'Learning Curves for Gap (' + alg_name + ')'\n",
    "\n",
    "    # Cross validation with 25 iterations to get smoother mean test and train\n",
    "    # score curves, each time with 20% data randomly selected as a validation set.\n",
    "    cv = cross_validation.ShuffleSplit(X.shape[0], n_iter=25, test_size=0.2, random_state=0)\n",
    "    estimator = alg\n",
    "    plot_learning_curve(estimator, alg_name, title, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "        \n",
    "def plot_learning_curve(estimator, alg_name, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "                An object of that type which is cloned for each validation.\n",
    "\n",
    "    alg_name : name of the algorithm being tested\n",
    "    \n",
    "    title : string\n",
    "            Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "           Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "         If an integer is passed, it is the number of folds (defaults to 3).\n",
    "         Specific cross-validation objects can be passed, see\n",
    "         sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "             Number of jobs to run in parallel (default 1).\n",
    "             \n",
    "    train_sizes : array, optional\n",
    "                  Sizes of train set to use for generating the learning curve plot \n",
    "    \"\"\"\n",
    "    # Plot Learning Curve\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"R^2 Score\")\n",
    "    \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, \n",
    "                                                            n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    stop = timeit.default_timer()\n",
    "    h, m, s = conv_seconds(stop - start)\n",
    "    print 'Learning Curves Runtime: {0:d}h:{1:02d}m:{2:02d}s\\n\\n' .format(h, m, s) \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    \n",
    "    # Print Scores\n",
    "    for train_size, train_score, test_score in zip(train_sizes, train_scores_mean, test_scores_mean):\n",
    "        print ('Train Size: {0:7d} Train Score: {1:.3f} Test Score: {2:.3f}' .format(int(train_size), float(train_score), float(test_score)))\n",
    "    \n",
    "    return plt\n",
    "\n",
    "\n",
    "def conv_seconds(seconds):\n",
    "    '''\n",
    "    Convert seconds to hours, minutes, seconds format.\n",
    "    '''\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return (int(h),int(m),int(s))\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator, X, y, param_name, param_range, \n",
    "                          scoring, plot_title, x_label, y_label, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the validation curve for one hyperparameter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "                An object of that type which is cloned for each validation.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    param_name : string with the name of the hyperparameter\n",
    "    \n",
    "    param_range : array with values for the hyperparameter\n",
    "    \n",
    "    scoring : scoring function to use\n",
    "    \n",
    "    plot_title : string\n",
    "            Title for the chart.\n",
    "            \n",
    "    x_label: label for x-axis of the plot\n",
    "    \n",
    "    y_label: lable for y-axis of the plot\n",
    "    \n",
    "    n_jobs : integer, optional\n",
    "             Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cross validation with 10 iterations to get smoother mean test and train\n",
    "    # score curves, each time with 20% data randomly selected as a validation set.\n",
    "    cv = cross_validation.ShuffleSplit(X.shape[0], n_iter=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    train_scores, test_scores = validation_curve(estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "                                                 cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "    stop = timeit.default_timer()\n",
    "    h, m, s = conv_seconds(stop - start)\n",
    "    print 'Validation Curves Runtime: {0:d}h:{1:02d}m:{2:02d}s\\n\\n' .format(h, m, s)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Print Scores\n",
    "    for param, train_score, test_score in zip(param_range, train_scores_mean, test_scores_mean):\n",
    "        print ('{0}: {1:7d}    Train Score: {2:.3f} Test Score: {3:.3f}' .format(param_name, int(param), float(train_score), float(test_score)))\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer with Learning Rate, Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subset the training data for faster turnaround.\n",
    "#train_subset  = (train_dataset.shape[0])/10\n",
    "train_subset  = 6000\n",
    "\n",
    "# Constants\n",
    "num_weights      = train_dataset.shape[1]\n",
    "\n",
    "# Hyper Parameters\n",
    "learning_rate = 1e-4\n",
    "l2loss_lambda = 1e-4\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Load the training, validation and test data into constants\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :], dtype=tf.float64)\n",
    "    tf_train_labels  = tf.constant(train_labels[:train_subset], dtype=tf.float64)\n",
    "    tf_valid_dataset = tf.constant(valid_dataset, dtype=tf.float64)\n",
    "    tf_test_dataset  = tf.constant(test_dataset, dtype=tf.float64)\n",
    "  \n",
    "    # Initialize weight matrix using random values following a (truncated)\n",
    "    # normal distribution. The biases get initialized to zero.\n",
    "    weights = tf.Variable(tf.truncated_normal([num_weights, 1], dtype=tf.float64))\n",
    "    biases  = tf.Variable(tf.zeros([1], dtype=tf.float64))\n",
    "  \n",
    "    # Regularization loss\n",
    "    beta    = tf.Variable(tf.zeros([1], dtype=tf.float64))  \n",
    "    regularization = l2loss_lambda * tf.nn.l2_loss(weights) \n",
    "\n",
    " \n",
    "    # Training computation.\n",
    "    # We multiply the inputs with the weight matrix, and add biases. \n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  \n",
    "    # Mean squared error + Regularization\n",
    "    loss = (tf.reduce_sum(tf.pow(tf.reshape(logits,[-1])-tf_train_labels, 2))/ train_subset) +  regularization\n",
    "    \n",
    "    \n",
    "    # Minimize cost + l2_loss using gradient descent.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = logits\n",
    "    valid_prediction = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "    test_prediction  = tf.matmul(tf_test_dataset, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 6.469%\n",
      "Training accuracy: 6.469%\n",
      "Validation accuracy: 6.893%\n",
      "Test accuracy: 8.693%\n",
      "Loss at step 100000: 0.241%\n",
      "Training accuracy: 0.241%\n",
      "Validation accuracy: 0.129%\n",
      "Test accuracy: 0.189%\n",
      "Loss at step 200000: 0.158%\n",
      "Training accuracy: 0.157%\n",
      "Validation accuracy: 0.127%\n",
      "Test accuracy: 0.197%\n",
      "Loss at step 300000: 0.128%\n",
      "Training accuracy: 0.127%\n",
      "Validation accuracy: 0.131%\n",
      "Test accuracy: 0.203%\n",
      "Loss at step 400000: 0.114%\n",
      "Training accuracy: 0.114%\n",
      "Validation accuracy: 0.135%\n",
      "Test accuracy: 0.207%\n",
      "Loss at step 500000: 0.108%\n",
      "Training accuracy: 0.107%\n",
      "Validation accuracy: 0.137%\n",
      "Test accuracy: 0.211%\n",
      "\t\tMEAN^2\t\tR2\t\tMAPE\n",
      "TRAIN     \t0.107\t\t0.912\t\t0.023\n",
      "TEST      \t0.211\t\t0.813\t\t0.468\n"
     ]
    }
   ],
   "source": [
    "num_steps = 500001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the\n",
    "    # biases. \n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "        # and get the loss value and the training predictions returned as numpy\n",
    "        # arrays.\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if (step % 100000 == 0):\n",
    "            print('Loss at step %d: %.3f%%' % (step, l))\n",
    "            print('Training MSE: %.3f%%' % metrics.mean_squared_error(predictions, train_labels[:train_subset]))\n",
    "            print('Validation MSE: %.3f%%' % metrics.mean_squared_error(valid_prediction.eval(), valid_labels))\n",
    "            #print('Test MSE: %.3f%%' % metrics.mean_squared_error(test_prediction.eval(), test_labels))\n",
    "            \n",
    "            valid_predictions = valid_prediction.eval()\n",
    "            test_predictions = test_prediction.eval()\n",
    "            \n",
    "    print_score(train_labels[:train_subset], predictions.reshape(-1), test_labels, test_predictions.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, dtype=tf.float64)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape, dtype=tf.float64)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Constants\n",
    "num_weights = train_dataset.shape[1]\n",
    "\n",
    "# Hyper Parameters\n",
    "learning_rate = 1e-5\n",
    "l2loss_lambda = 0 #1e-4\n",
    "batch_size = 10000\n",
    "num_relus  = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float64, shape=(batch_size, num_weights))\n",
    "    tf_train_labels  = tf.placeholder(tf.float64, shape=(batch_size, 1))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset  = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    weights1 = weight_variable([num_weights, num_relus])\n",
    "    biases1  = bias_variable([num_relus])\n",
    "    weights2 = weight_variable([num_relus, 1])\n",
    "    biases2  = bias_variable([1])\n",
    "        \n",
    "    # Regularization loss\n",
    "    beta    = tf.Variable(tf.zeros([1], dtype=tf.float64))  \n",
    "    l2_loss = l2loss_lambda * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))   \n",
    "\n",
    "    # Training computation.\n",
    "    to_hidden   = tf.matmul(tf_train_dataset, weights1) + biases1\n",
    "    from_hidden = tf.nn.relu(to_hidden)\n",
    "\n",
    "    # Introduce dropout before readout layer\n",
    "    keep_prob = tf.placeholder(tf.float64)\n",
    "    from_drop = tf.nn.dropout(from_hidden, keep_prob)\n",
    "                           \n",
    "    logits      = tf.matmul(from_drop, weights2) + biases2\n",
    "    \n",
    "    # Mean squared error + Regularization\n",
    "    loss = tf.reduce_sum(tf.pow(tf.reshape(logits,[-1])-tf.reshape(tf_train_labels,[-1]), 2)/ batch_size) +  l2_loss\n",
    "  \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = logits\n",
    "    valid_prediction = tf.matmul(\n",
    "                       tf.nn.relu(\n",
    "                       tf.matmul(tf_valid_dataset, weights1) + biases1), weights2) + biases2\n",
    "    test_prediction = tf.matmul(\n",
    "                      tf.nn.relu(\n",
    "                      tf.matmul(tf_test_dataset, weights1) + biases1), weights2) + biases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 1.035%\n",
      "Training MSE: 1.035%\n",
      "Validation MSE: 1.451%\n",
      "Loss at step 20000: 0.511%\n",
      "Training MSE: 0.511%\n",
      "Validation MSE: 0.508%\n",
      "Loss at step 40000: 0.252%\n",
      "Training MSE: 0.252%\n",
      "Validation MSE: 0.351%\n",
      "Loss at step 60000: 0.187%\n",
      "Training MSE: 0.187%\n",
      "Validation MSE: 0.306%\n",
      "Loss at step 80000: 0.120%\n",
      "Training MSE: 0.120%\n",
      "Validation MSE: 0.278%\n",
      "Loss at step 100000: 0.163%\n",
      "Training MSE: 0.163%\n",
      "Validation MSE: 0.257%\n",
      "\t\tMEAN^2\t\tR2\t\tMAPE\n",
      "TRAIN     \t0.163\t\t0.808\t\t0.033\n",
      "TEST      \t0.196\t\t0.827\t\t0.322\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter\n",
    "num_steps = 100001\n",
    "keep_probvalue = 0.5\n",
    "\n",
    "with tf.Session(graph=graph) as session2:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels.reshape(-1,1)[offset:(offset + batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob: 0.5}\n",
    "        _, l, predictions = session2.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "      \n",
    "        if (step % 20000 == 0):\n",
    "            print('Loss at step %d: %.3f%%' % (step, l))\n",
    "            print('Training MSE: %.3f%%' % metrics.mean_squared_error(predictions, train_labels.reshape(-1,1)[offset:(offset + batch_size), :]))\n",
    "            print('Validation MSE: %.3f%%' % metrics.mean_squared_error(valid_prediction.eval(), valid_labels))\n",
    "            #print('Test MSE: %.3f%%' % metrics.mean_squared_error(test_prediction.eval(), test_labels))\n",
    "                        \n",
    "            valid_predictions = valid_prediction.eval()\n",
    "            test_predictions = test_prediction.eval()\n",
    "            \n",
    "    print_score(train_labels[offset:(offset + batch_size)], predictions.reshape(-1), test_labels, test_predictions.reshape(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
