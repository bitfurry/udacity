{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT THIS NOTEBOOK\n",
    "## Purpose\n",
    "This notebook attempts to fit various machine learning models on the data set.    \n",
    "Results of the model fitting are analyzed.\n",
    "## Input\n",
    "'data_set.pickle' generated by 'data_processing.ipynb'.\n",
    "## Output\n",
    "Results of model fitting: parameters and scores.\n",
    "## Tasks Performed\n",
    "* Load library packages\n",
    "* Load pickle file\n",
    "* Split data into train & test sets\n",
    "    * Train: weeks 1 & 2, Test: week 3\n",
    "    * Perform feature scaling\n",
    "* Implement functions for common tasks\n",
    "    * Scoring\n",
    "    * Learning curves\n",
    "    * Cross validation\n",
    "    * Hyperparameter selection\n",
    "* Fit models\n",
    "    * Linear\n",
    "    * Random Forest Regressor\n",
    "    * K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD LIBRARY PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in packages from os, numpy, pandas, matplotlib, seaborn, sklearn, scipy & six\n"
     ]
    }
   ],
   "source": [
    "# Import the required library packages\n",
    "import os\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "print 'Read in packages from os, numpy, pandas, matplotlib, seaborn, sklearn & six'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PICKLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ptrain_set (199584, 55)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'data_set.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    pdata_set = save['data_set']\n",
    "    del save\n",
    "    print 'Loaded ptrain_set', pdata_set.shape\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['district_id', 'num_day', 'time_slot', 'week_day', 'demand',\n",
       "       'demand_t-1', 'demand_t-2', 'demand_t-3', 'supply', 'supply_t-1',\n",
       "       'supply_t-2', 'supply_t-3', 'gap', 'weather', 'temperature',\n",
       "       'pollution', 'poi_pc1', 'poi_pc2', 'poi_pc3', 'poi_pc4',\n",
       "       'poi_cluster', 'tj_lvl1', 'tj_lvl2', 'tj_lvl3', 'tj_lvl4', 'dist_0',\n",
       "       'dist_1', 'dist_2', 'dist_3', 'dist_4', 'dist_5', 'dist_6',\n",
       "       'numday_0', 'numday_1', 'numday_2', 'numday_3', 'numday_4', 'ts_0',\n",
       "       'ts_1', 'ts_2', 'ts_3', 'ts_4', 'ts_5', 'ts_6', 'ts_7', 'weekday_0',\n",
       "       'weekday_1', 'weekday_2', 'poi_0', 'poi_1', 'poi_2', 'wthr_0',\n",
       "       'wthr_1', 'wthr_2', 'wthr_3'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata_set.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA INTO TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use weeks 1 & 2 for training, week 3 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train, X_test: (133056, 55) (66528, 55) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_days     = range(1,15)\n",
    "test_days      = range(15, 22)\n",
    "\n",
    "X_train     = pdata_set[(pdata_set['num_day'].isin(train_days))]\n",
    "X_test      = pdata_set[(pdata_set['num_day'].isin(test_days))]\n",
    "\n",
    "print \"Shape of X_train, X_test:\", X_train.shape, X_test.shape, \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scaled features for train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gap_predictors = ['demand_t-1', 'demand_t-2', 'demand_t-3',\n",
    "                  'supply_t-1', 'supply_t-2', 'supply_t-3',\n",
    "                  'poi_pc1', 'poi_pc2',\n",
    "                  'tj_lvl1', 'tj_lvl2', 'tj_lvl3',\n",
    "                  'ts_0', 'ts_1', 'ts_2', 'ts_3', 'ts_4', 'ts_5', 'ts_6', 'ts_7',\n",
    "                  'pollution', 'temperature',\n",
    "                  'wthr_0', 'wthr_1', 'wthr_2', 'wthr_3'\n",
    "                 ]  \n",
    "\n",
    "gX_train = []\n",
    "gy_train = []\n",
    "gX_test  = []\n",
    "gy_test  = []\n",
    "\n",
    "# Use StandardScaler to achieve zero mean and unit variance\n",
    "# Generate two scalers: input and target\n",
    "input_scaler = StandardScaler().fit(pdata_set[gap_predictors])\n",
    "target_scaler = StandardScaler().fit(pdata_set['gap'])\n",
    "\n",
    "# Scale both training & test data\n",
    "gX_train  = input_scaler.transform(X_train[gap_predictors])\n",
    "gy_train  = target_scaler.transform(X_train['gap'])\n",
    "\n",
    "gX_test = input_scaler.transform(X_test[gap_predictors])\n",
    "gy_test = target_scaler.transform(X_test['gap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENT FUNCTIONS FOR COMMON TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape_score(exp, pred, q):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate the MAPE score value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exp  : Array containing expected values\n",
    "    pred : Array containing predicted values\n",
    "    q    : Constant representing (number of days * number of time slots) - 1\n",
    "    \"\"\"\n",
    "    \n",
    "    mape = 0.0\n",
    "    n = 66.0\n",
    "    \n",
    "    for gap, gapX in zip(exp, pred):\n",
    "        if gap > 0:\n",
    "            mape += 1.0 * abs((gap-gapX)/gap)\n",
    "    return (mape/(n*q))\n",
    "\n",
    "\n",
    "def print_score(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Present the MSE, R^2 and MAPE scores for train & test sets as a table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train      : Array containing expected values for train set\n",
    "    y_pred_train : Array containing predicted values for train set\n",
    "    y_test       : Array containing expected values for test set\n",
    "    y_pred_test  : Array containing predicted values for test set\n",
    "    \"\"\"\n",
    "    \n",
    "    m2score_train    = metrics.mean_squared_error(y_train,    y_pred_train)\n",
    "    m2score_test     = metrics.mean_squared_error(y_test,     y_pred_test)\n",
    "\n",
    "\n",
    "    r2score_train    = metrics.r2_score(y_train,    y_pred_train)\n",
    "    r2score_test     = metrics.r2_score(y_test,     y_pred_test)\n",
    "\n",
    "    # Assumes data is for 144 time slots, 14 days (train), 6 days (test)\n",
    "    mpscore_train    = mape_score(y_train,    y_pred_train, ((144*14)-1))\n",
    "    mpscore_test     = mape_score(y_test,     y_pred_test, ((144*6)-1))\n",
    "\n",
    "\n",
    "    sets_list = [\"TRAIN\", \"TEST\"]\n",
    "\n",
    "    m2_scores = [m2score_train, m2score_test]\n",
    "    r2_scores = [r2score_train, r2score_test]\n",
    "    mp_scores = [mpscore_train, mpscore_test]\n",
    "\n",
    "\n",
    "    print '\\t\\tMEAN^2\\t\\tR2\\t\\tMAPE'\n",
    "\n",
    "    for s, m, r, mp in zip(sets_list, m2_scores, r2_scores, mp_scores):\n",
    "        print '{0:10}\\t{1:.2f}\\t\\t{2:.2f}\\t\\t{3:.2f}' .format(s, m, r, mp)\n",
    "\n",
    "        \n",
    "def eval_score(y_train, y_pred_train, y_test, y_pred_test):\n",
    "        \n",
    "    \"\"\"\n",
    "    Present the MSE, R^2 and MAPE scores for train & test sets as a table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train      : Array containing expected values for train set\n",
    "    y_pred_train : Array containing predicted values for train set\n",
    "    y_test       : Array containing expected values for test set\n",
    "    y_pred_test  : Array containing predicted values for test set\n",
    "    \"\"\"\n",
    "    \n",
    "    m2score_train    = metrics.mean_squared_error(y_train,    y_pred_train)\n",
    "    m2score_test     = metrics.mean_squared_error(y_test,     y_pred_test)\n",
    "\n",
    "\n",
    "    r2score_train    = metrics.r2_score(y_train,    y_pred_train)\n",
    "    r2score_test     = metrics.r2_score(y_test,     y_pred_test)\n",
    "\n",
    "    mpscore_train    = mape_score(y_train,    y_pred_train, ((144*14)-1))\n",
    "    mpscore_test     = mape_score(y_test,     y_pred_test, ((144*6)-1))\n",
    "\n",
    "\n",
    "    sets_list = [\"TRAIN\", \"TEST\"]\n",
    "\n",
    "    m2_scores = [m2score_train, m2score_test]\n",
    "    r2_scores = [r2score_train, r2score_test]\n",
    "    mp_scores = [mpscore_train, mpscore_test]\n",
    "\n",
    "\n",
    "    print '\\t\\tMEAN^2\\t\\tR2\\t\\tMAPE'\n",
    "\n",
    "\n",
    "    for s, m, r, mp in zip(sets_list, m2_scores, r2_scores, mp_scores):\n",
    "        print '{0:10}\\t{1:.2f}\\t\\t{2:.2f}\\t\\t{3:.2f}' .format(s, m, r, mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a scorer function using the MAPE metric\n",
    "# Use the training data size (144 time slots * 14 days) for q value\n",
    "from sklearn.metrics import make_scorer\n",
    "mape_scorer = make_scorer(mape_score, greater_is_better=False, q=((144*14)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(train_set, test_set, predictors, exp_col, fitfunc, *fitargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate predictions, evaluate scores and present results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_set  : Dataframe for train set\n",
    "    test_set   : Dataframe for test set\n",
    "    predictors : Array containing columns representing the input features to be used for prediction\n",
    "    exp_col    : Column name containing the expected value \n",
    "    fitfunc    : Model used for fitting\n",
    "    fitargs    : Arguments passed to the model\n",
    "    \"\"\"\n",
    "        \n",
    "    # Generate dataframe for train & test\n",
    "    Xtrain_df    = train_set[predictors]\n",
    "    Xtest_df     = test_set[predictors]\n",
    "    \n",
    "    # Generate predictions for train & test\n",
    "    y_pred_train    = fitfunc(Xtrain_df,    *fitargs)\n",
    "    y_pred_test     = fitfunc(Xtest_df,     *fitargs)\n",
    "\n",
    "    # Extract expected train & test values\n",
    "    y_train    = train_set[exp_col]\n",
    "    y_test     = test_set[exp_col]\n",
    "\n",
    "    m2score_train    = metrics.mean_squared_error(y_train,    y_pred_train)\n",
    "    m2score_test     = metrics.mean_squared_error(y_test,     y_pred_test)\n",
    "\n",
    "\n",
    "    r2score_train    = metrics.r2_score(y_train,    y_pred_train)\n",
    "    r2score_test     = metrics.r2_score(y_test,     y_pred_test)\n",
    "\n",
    "    mpscore_train    = mape_score(y_train,    y_pred_train, ((144*14)-1))\n",
    "    mpscore_test     = mape_score(y_test,     y_pred_test, ((144*6)-1))\n",
    "\n",
    "\n",
    "    sets_list = [\"TRAIN\", \"TEST\"]\n",
    "\n",
    "    m2_scores = [m2score_train, m2score_test]\n",
    "    r2_scores = [r2score_train, r2score_test]\n",
    "    mp_scores = [mpscore_train, mpscore_test]\n",
    "\n",
    "\n",
    "    print '\\t\\tMEAN^2\\t\\tR2\\t\\tMAPE'\n",
    "\n",
    "\n",
    "    for s, m, r, mp in zip(sets_list, m2_scores, r2_scores, mp_scores):\n",
    "        print '{0:10}\\t{1:.2f}\\t\\t{2:.2f}\\t\\t{3:.2f}' .format(s, m, r, mp)\n",
    "    \n",
    "    return(y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING CURVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "def plot_validation_curve(estimator, X, y, param_name, param_range, \n",
    "                          scoring, plot_title, x_label, y_label, n_jobs=-1):\n",
    "    \n",
    "    # Cross validation with 25 iterations to get smoother mean test and train\n",
    "    # score curves, each time with 20% data randomly selected as a validation set.\n",
    "    cv = cross_validation.ShuffleSplit(X.shape[0], n_iter=25, test_size=0.2, random_state=0)\n",
    "    \n",
    "    train_scores, test_scores = validation_curve(estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "                                                 cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "                An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "            Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "           Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "         If an integer is passed, it is the number of folds (defaults to 3).\n",
    "         Specific cross-validation objects can be passed, see\n",
    "         sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "             Number of jobs to run in parallel (default 1).\n",
    "             \n",
    "    train_sizes : array, optional\n",
    "                  Sizes of train set to use for generating the learning curve plot \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"R^2 Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMAND, SUPPLY PREDICTIONS & GAP FORECASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_error(gapy_pred_train, gapy_pred_test):\n",
    "    \n",
    "    Xerr_train = pd.DataFrame()\n",
    "    Xerr_test  = pd.DataFrame()\n",
    "    \n",
    "    Xerr_train = X_train.copy()\n",
    "    Xerr_test  = X_test.copy()\n",
    "    \n",
    "    # Drop columns that will not be used for analysis\n",
    "    Xerr_train.drop(['weather', 'temperature', 'pollution', \n",
    "                     'demand_t-1', 'demand_t-2', 'demand_t-3', \n",
    "                     'supply_t-1', 'supply_t-2', 'supply_t-3'],\n",
    "                    axis=1, inplace=True)\n",
    "    \n",
    "    Xerr_test.drop(['weather', 'temperature', 'pollution', \n",
    "                    'demand_t-1', 'demand_t-2', 'demand_t-3', \n",
    "                    'supply_t-1', 'supply_t-2', 'supply_t-3'], \n",
    "                   axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Create new columns that store errors\n",
    "    Xerr_train['gap_error'] = X_train['gap']    - gapy_pred_train\n",
    "    Xerr_test['gap_error'] = X_test['gap']    - gapy_pred_test\n",
    "    \n",
    "    print '\\nTrain error correlation matrix:\\n', Xerr_train.corr()\n",
    "    print '\\nTest error correlation matrix:\\n', Xerr_test.corr()    \n",
    "  \n",
    "    print '\\nTest Error Joint Plot\\n'\n",
    "    for y in ['demand', 'gap', 'supply', 'district_id', 'num_day', 'time_slot', 'week_day', 'poi_cluster', 'congestion']:\n",
    "        g = sns.jointplot('gap_error', y, data=Xerr_train, kind=\"reg\",color=\"r\", size=3)\n",
    "    plt.show()\n",
    "    \n",
    "    print '\\nTrain Error Joint Plot\\n'\n",
    "    for y in ['demand', 'gap', 'supply', 'district_id', 'num_day', 'time_slot', 'week_day', 'poi_cluster', 'congestion']:\n",
    "        g = sns.jointplot('gap_error', y, data=Xerr_test, kind=\"reg\",color=\"r\", size=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Demand Supply Gap Metrics based on provided fit functions\n",
    "# Assumes expected values for gap is in namesake column\n",
    "def gap_estimate(**kwargs):\n",
    "    \n",
    "    gX_train     = kwargs[\"gX_train\"]\n",
    "    gX_test      = kwargs[\"gX_test\"]\n",
    "    g_fitfunc    = kwargs[\"g_fitfunc\"]\n",
    "    \n",
    "    print \"\\n\\nGAP FORECASTING\"\n",
    "    print     \"===============\"\n",
    "\n",
    "    # Generate predictions for train & test sets\n",
    "    gy_pred_train    = gap_scaler.inverse_transform(g_fitfunc.predict(gX_train))\n",
    "    gy_pred_test     = gap_scaler.inverse_transform(g_fitfunc.predict(gX_test))\n",
    "\n",
    "    # Extract expected train & test values\n",
    "    gy_train    = X_train['gap']\n",
    "    gy_test     = X_test['gap']\n",
    "\n",
    "    # Evaluate scores and print results\n",
    "    print_score(gy_train, gy_pred_train, gy_test, gy_pred_test)\n",
    "   \n",
    "    #analyze_error(gy_pred_train, gy_pred_test)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# Generate Demand Supply Gap Metrics based on provided fit functions\n",
    "# Assumes expected values for demand, supply, gap are in namesake columns\n",
    "def gap_forecast(**kwargs):\n",
    "    \n",
    "    X_train      = kwargs[\"train_set\"]\n",
    "    X_test       = kwargs[\"test_set\"]\n",
    "    r_predictors = kwargs[\"demand_predictors\"]\n",
    "    a_predictors = kwargs[\"supply_predictors\"]\n",
    "    r_fitfunc    = kwargs[\"rfit_func\"]\n",
    "    r_fitargs    = kwargs[\"rfit_args\"]\n",
    "    a_fitfunc    = kwargs[\"afit_func\"]\n",
    "    a_fitargs    = kwargs[\"afit_args\"]\n",
    "    \n",
    "    print \"\\n\\nDEMAND FORECASTING\"\n",
    "    print     \"==================\"\n",
    "\n",
    "    ry_pred_train, ry_pred_test = predict_score(X_train, X_test, r_predictors, 'demand', r_fitfunc, *r_fitargs)\n",
    "\n",
    "    print \"\\n\\nSUPPLY FORECASTING\"\n",
    "    print     \"==================\"\n",
    "\n",
    "    ay_pred_train, ay_pred_test = predict_score(X_train, X_test, a_predictors, 'supply', a_fitfunc, *a_fitargs)\n",
    "\n",
    "    print \"\\n\\nGAP FORECASTING\"\n",
    "    print     \"===============\"\n",
    "\n",
    "    gapy_pred_train    = [r - a for r, a in zip(ry_pred_train,    ay_pred_train)]\n",
    "    gapy_pred_test     = [r - a for r, a in zip(ry_pred_test,     ay_pred_test)]\n",
    "\n",
    "    gapy_train    = X_train['gap']\n",
    "    gapy_test     = X_test['gap']\n",
    "\n",
    "    eval_score(gapy_train, gapy_pred_train, gapy_test, gapy_pred_test)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate learning curves by varying training sizes\n",
    "# Use Training vs Cross-validation curves\n",
    "def generate_learningcurves(**kwargs):    \n",
    "   \n",
    "    gX_train      = kwargs[\"gX_train\"]\n",
    "    gy_train      = kwargs[\"gy_train\"]\n",
    "        \n",
    "    alg           = kwargs[\"alg\"]\n",
    "    alg_name      = kwargs[\"alg_name\"]\n",
    "          \n",
    "    # Plot learning curve - Demand\n",
    "    X, y = gX_train, gy_train\n",
    "\n",
    "    title = 'Learning Curves for Gap (' + alg_name + ')'\n",
    "\n",
    "    # Cross validation with 25 iterations to get smoother mean test and train\n",
    "    # score curves, each time with 20% data randomly selected as a validation set.\n",
    "    cv = cross_validation.ShuffleSplit(X.shape[0], n_iter=25, test_size=0.2, random_state=0)\n",
    "\n",
    "    estimator = alg\n",
    "    plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=-1, train_sizes=np.linspace(.01, 1.0, 20))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate learning curves by varying training sizes\n",
    "# Use Training vs Cross-validation curves\n",
    "def generate_traintestscores(**kwargs):    \n",
    "   \n",
    "    gX_train      = kwargs[\"gX_train\"]\n",
    "    gy_train      = kwargs[\"gy_train\"]\n",
    "    gX_test       = kwargs[\"gX_test\"]\n",
    "    gy_test       = kwargs[\"gy_test\"]\n",
    "        \n",
    "    alg           = kwargs[\"alg\"]\n",
    "    alg_name      = kwargs[\"alg_name\"]\n",
    "    \n",
    "    # Create training set of increasing sizes\n",
    "    train_size_set = [10000, 20000, 40000, 60000, 80000, 93324]\n",
    "\n",
    "    Xg_train_set = []\n",
    "    yg_train_set = []   \n",
    "    Xg_test = gX_test\n",
    "    yg_test = gy_test\n",
    "\n",
    "\n",
    "    for size in train_size_set: \n",
    "        Xg_train_set.append(gX_train[:size])\n",
    "        yg_train_set.append(gy_train[:size])\n",
    "    \n",
    "    # Train Gap Forecaster\n",
    "    print ('\\nTraining Gap Forecaster - {}\\n' .format(alg_name))\n",
    "\n",
    "    for train_size, Xg_train, yg_train in zip(train_size_set, Xg_train_set, yg_train_set):\n",
    "        clf = alg.fit(Xg_train, yg_train)\n",
    "    \n",
    "        # Scores\n",
    "        train_score = clf.score(Xg_train, yg_train)\n",
    "        test_score  = clf.score(Xg_test, yg_test)\n",
    "        print ('Train Size: {0:.3f} Train Score: {1:.3f} Test Score: {2:.3f}' .format(train_size, train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_hyperparams(**kwargs):\n",
    "    \n",
    "    gX_train      = kwargs['gX_train']\n",
    "    gy_train      = kwargs['gy_train']\n",
    "    gX_test       = kwargs[\"gX_test\"]\n",
    "    gy_test       = kwargs[\"gy_test\"]\n",
    "\n",
    "    \n",
    "    alg           = kwargs['alg']\n",
    "    alg_name      = kwargs['alg_name']\n",
    "    param_grid    = kwargs['param_grid']\n",
    "    scoring_func  = kwargs['scoring_func']\n",
    "    \n",
    "    # GAP\n",
    "    # Use nested cross validation - 5x2 cross validation\n",
    "\n",
    "    g_gs = GridSearchCV(estimator=alg,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring=scoring_func,\n",
    "                  cv=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "    scores = cross_val_score(estimator=g_gs,\n",
    "                         X=gX_train,\n",
    "                         y=gy_train,\n",
    "                         scoring=scoring_func,\n",
    "                         cv=5)\n",
    "\n",
    "    g_gs = g_gs.fit(X=gX_train, y=gy_train)\n",
    "\n",
    "    print 'Best Estimator (Demand):\\n', g_gs.best_estimator_\n",
    "    print('CV accuracy (Demand): %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "   \n",
    "    # Generate Learning Curves - Demand & Supply\n",
    "    generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                            alg=g_gs.best_estimator_, alg_name=alg_name)\n",
    "    \n",
    "    generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                             alg=g_gs.best_estimator_, alg_name=alg_name)\n",
    "    \n",
    "    # Print Scores   \n",
    "    gap_estimate(gX_train=gX_train, gX_test=gX_test, g_fitfunc=g_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETS - Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forests only supports MSE score for deciding splits\n",
    "generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                        alg=RandomForestRegressor(), alg_name=\"Random Forests\")\n",
    "\n",
    "generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                         alg=RandomForestRegressor(), alg_name=\"Random Forests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV - Demand\n",
    "# Specify parameters\n",
    "param_grid = {'n_estimators'      : [50],\n",
    "              'max_features'      : [0.75, 1.0],\n",
    "              'max_depth'         : [3],\n",
    "              'min_samples_split' : [3],\n",
    "              'random_state'      : [0]}\n",
    "             \n",
    "alg = RandomForestRegressor()\n",
    "\n",
    "# Only mse is supported for the RandomForestRegressor\n",
    "# Use MAPE as scoring function for GridSearchCV, cross_val_score\n",
    "select_hyperparams(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                   alg=alg, alg_name='Random Forests', param_grid=param_grid, scoring_func=mape_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decision Trees only supports MSE score for deciding splits\n",
    "generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                        alg=DecisionTreeRegressor(), alg_name=\"Decision Trees\")\n",
    "\n",
    "generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                         alg=DecisionTreeRegressor(), alg_name=\"Decision Trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV - Gap\n",
    "# Specify parameters\n",
    "param_grid = {'max_features'      : [0.25, 0.5, 0.75, 1.0],\n",
    "              'max_depth'         : [5, 10, 15, 20, 25],\n",
    "              'min_samples_split' : [2, 3, 4, 5, 10],\n",
    "              'random_state'      : [0]}\n",
    "             \n",
    "alg = DecisionTreeRegressor()\n",
    "\n",
    "# Only mse is supported for the DecisionTreeRegressor\n",
    "# Use MAPE as scoring function for GridSearchCV, cross_val_score\n",
    "select_hyperparams(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                   alg=alg, alg_name='Decision Trees', param_grid=param_grid, scoring_func=mape_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEcCAYAAADk05IoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntLAopZTqVlpYlFJKdav/AeW8N7XhfeFmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ee200e510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gap Forecaster - KNN\n",
      "\n",
      "Train Size: 10000.000 Train Score: 0.743 Test Score: 0.178\n",
      "Train Size: 20000.000 Train Score: 0.879 Test Score: 0.664\n",
      "Train Size: 40000.000 Train Score: 0.881 Test Score: 0.675\n",
      "Train Size: 60000.000 Train Score: 0.886 Test Score: 0.722\n",
      "Train Size: 80000.000 Train Score: 0.889 Test Score: 0.734\n",
      "Train Size: 93324.000 Train Score: 0.892 Test Score: 0.739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# KNN defaults to R^2 score\n",
    "generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                        alg=KNeighborsRegressor(), alg_name=\"KNN\")\n",
    "\n",
    "generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                         alg=KNeighborsRegressor(), alg_name=\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling for input features\n",
    "# Generate scaled features for train & test sets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "few_predictors = ['demand_t-1', 'demand_t-2', 'demand_t-3',\n",
    "                  'supply_t-1', 'supply_t-2', 'supply_t-3',\n",
    "                  'weekday_0', 'weekday_1', 'weekday_2',\n",
    "                  'ts_7', 'ts_6', 'ts_5', 'ts_4', 'ts_3', 'ts_2', 'ts_1', 'ts_0',\n",
    "                  'dist_6', 'dist_5', 'dist_4', 'dist_3', 'dist_2', 'dist_1', 'dist_0'] \n",
    "\n",
    "gX_train = []\n",
    "gy_train = []\n",
    "gX_test  = []\n",
    "gy_test  = []\n",
    "\n",
    "# Normalize features - both training & test\n",
    "g_scaler = StandardScaler().fit(ptrain_set[few_predictors])\n",
    "gap_scaler = StandardScaler().fit(ptrain_set['gap'])\n",
    "\n",
    "# Input Samples and Target Values for Gap(g)\n",
    "gX_train  = g_scaler.transform(X_train[few_predictors])\n",
    "gy_train  = gap_scaler.transform(X_train['gap'])\n",
    "\n",
    "gX_test = g_scaler.transform(X_test[few_predictors])\n",
    "gy_test = gap_scaler.transform(X_test['gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "plot_validation_curve(estimator=KNeighborsRegressor(), X=gX_train, y=gy_train, \n",
    "                      param_name='n_neighbors', param_range=[3,10,30,100,300,1000], \n",
    "                      scoring='r2', plot_title='KNN', x_label='# of neighbors', y_label='r2', \n",
    "                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV\n",
    "# Specify parameters\n",
    "param_grid = {'n_neighbors'       : [30, 90],\n",
    "              'weights'           : ['uniform'],\n",
    "              'metric'            : ['euclidean', 'minkowski']}\n",
    "\n",
    "alg = KNeighborsRegressor()\n",
    "\n",
    "# Use MAPE as scoring function\n",
    "select_hyperparams(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                   alg=alg, alg_name='KNN', param_grid=param_grid, scoring_func=mape_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fewer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling for input features\n",
    "# Generate scaled features for train & test sets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "few_predictors = ['demand_t-1', 'demand_t-2', 'demand_t-3',\n",
    "                  'supply_t-1', 'supply_t-2', 'supply_t-3',\n",
    "                  'weekday_0', 'weekday_1', 'weekday_2'] \n",
    "\n",
    "gX_train = []\n",
    "gy_train = []\n",
    "gX_test  = []\n",
    "gy_test  = []\n",
    "\n",
    "# Normalize features - both training & test\n",
    "g_scaler = StandardScaler().fit(ptrain_set[few_predictors])\n",
    "gap_scaler = StandardScaler().fit(ptrain_set['gap'])\n",
    "\n",
    "# Input Samples and Target Values for Gap(g)\n",
    "gX_train  = g_scaler.transform(X_train[few_predictors])\n",
    "gy_train  = gap_scaler.transform(X_train['gap'])\n",
    "\n",
    "gX_test = g_scaler.transform(X_test[few_predictors])\n",
    "gy_test = gap_scaler.transform(X_test['gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "plot_validation_curve(estimator=KNeighborsRegressor(), X=gX_train, y=gy_train, \n",
    "                      param_name='n_neighbors', param_range=[3,10,30,100,300,1000], \n",
    "                      scoring='r2', plot_title='KNN', x_label='# of neighbors', y_label='r2', \n",
    "                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use GridSearchCV\n",
    "# Specify parameters\n",
    "param_grid = {'n_neighbors'       : [30, 90],\n",
    "              'weights'           : ['uniform'],\n",
    "              'metric'            : ['euclidean', 'minkowski']}\n",
    "\n",
    "alg = KNeighborsRegressor()\n",
    "\n",
    "# Use MAPE as scoring function\n",
    "select_hyperparams(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                   alg=alg, alg_name='KNN', param_grid=param_grid, scoring_func=mape_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# SVM defaults to R^2 score\n",
    "generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                        alg=SVR(), alg_name=\"Support Vector Machines\")\n",
    "\n",
    "generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                         alg=SVR(), alg_name=\"Support Vector Machines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print Scores   \n",
    "g_gs = SVR().fit(X=gX_train, y=gy_train)\n",
    "\n",
    "gap_estimate(gX_train=gX_train, gX_test=gX_test, g_fitfunc=g_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Linear Regression defaults to R^2 score\n",
    "generate_learningcurves(gX_train=gX_train, gy_train=gy_train,\n",
    "                        alg=LinearRegression(), alg_name=\"Linear Regression\")\n",
    "\n",
    "generate_traintestscores(gX_train=gX_train, gy_train=gy_train, gX_test=gX_test, gy_test=gy_test,\n",
    "                         alg=LinearRegression(), alg_name=\"Linear Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print Scores   \n",
    "g_gs = LinearRegression().fit(X=gX_train, y=gy_train)\n",
    "\n",
    "gap_estimate(gX_train=gX_train, gX_test=gX_test, g_fitfunc=g_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK - SIMPLE AVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DEMAND FORECASTING\n",
      "==================\n",
      "\t\tMEAN^2\t\tR2\t\tMAPE\n",
      "TRAIN     \t784.82\t\t0.93\t\t3.24\n",
      "TEST      \t1159.29\t\t0.93\t\t1.36\n",
      "\n",
      "\n",
      "SUPPLY FORECASTING\n",
      "==================\n",
      "\t\tMEAN^2\t\tR2\t\tMAPE\n",
      "TRAIN     \t252.86\t\t0.96\t\t2.90\n",
      "TEST      \t273.82\t\t0.97\t\t1.22\n",
      "\n",
      "\n",
      "GAP FORECASTING\n",
      "===============\n",
      "\t\tMEAN^2\t\tR2\t\tMAPE\n",
      "TRAIN     \t508.04\t\t0.59\t\t4.40\n",
      "TEST      \t833.59\t\t0.74\t\t1.89\n"
     ]
    }
   ],
   "source": [
    "# Return simple average of previous 3 time slots\n",
    "def simple_average(df, t1, t2, t3):\n",
    "    return df.apply(lambda r: ((r[t1] + r[t2] + r[t3]) / 3.0), axis=1)\n",
    "\n",
    "# Define list of predictors for demand, supply\n",
    "r_predictors = ['district_id', 'num_day', 'time_slot', 'demand_t-1', 'demand_t-2', 'demand_t-3'] \n",
    "a_predictors = ['district_id', 'num_day', 'time_slot', 'supply_t-1', 'supply_t-2', 'supply_t-3']\n",
    "\n",
    "# Set arguments for gap forecasting function\n",
    "kwargs = {\"train_set\": X_train, \"test_set\": X_test, \n",
    "          \"demand_predictors\": r_predictors, \"supply_predictors\": a_predictors,\n",
    "          \"rfit_func\": simple_average, \"rfit_args\": ['demand_t-1','demand_t-2','demand_t-3'],\n",
    "          \"afit_func\": simple_average, \"afit_args\": ['supply_t-1','supply_t-2','supply_t-3']}\n",
    "\n",
    "gap_forecast(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
